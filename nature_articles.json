[
    {
        "URL": "https://www.nature.com/articles/d41586-024-03958-2",
        "title": "Stress can dull our capacity for joy: mouse brain patterns hint at why",
        "content": [
            "*Illustration_of_nerve_cells_from_the_cerebral_cortex_of_the_brain,_shown_in_blue",
            "Communication between neurons (illustration) in two separate brain regions is patchy in mice that are susceptible to severe stress. Credit: Juan Gaertner/Science Photo Library",
            "Joylessness triggered by stress creates a distinct brain signature, according to research in mice1. The study also reveals one brain pattern that seems to confer resilience to stress \u2014 and another that makes stressed animals less likely to feel pleasure, a core symptom of depression. ",
            "These findings, published today in Nature, offer clues as to how the brain gives rise to anhedonia, a resistance to enjoyment and pleasure. The results also provide a new avenue for treating the condition \u2014 if the findings are validated in humans.",
            "\u201cTheir approach in this study is spot on,\u201d says Conor Liston, a neuroscientist at Weill Cornell Medicine in New York City, who was not involved in the work. The experiments fill \u201ca big gap\u201d, he says. \u201cAnhedonia is something we don\u2019t understand very well.\u201d",
            "h2A distressing symptom",
            "More than 70% of people with severe depression experience anhedonia, which is also common in those with schizophrenia, Parkinson\u2019s disease and other neurological and psychiatric conditions.",
            "The symptom is notoriously difficult to treat, even in those taking medication, Liston says. \u201cAnhedonia is something that patients care about the most, and feel like it\u2019s least addressed by current treatments,\u201d he says.",
            "A journey into the causes and effects of depression",
            "To understand how the brain gives rise to anhedonia, Mazen Kheirbek, a systems neuroscientist at the University of California, San Francisco, and his colleagues studied mice that had been placed under stress by exposure to larger, more aggressive mice.",
            "Typically, mice have a sweet tooth and prefer sugar water over plain water if given the option. But some stressed mice instead preferred plain water \u2014 which Kheirbek and his colleagues interpreted as a rodent version of anhedonia. Other mice subjected to the same stress preferred the sugar water. The authors labelled these animals \u2018resilient\u2019.",
            "doi: https://doi.org/10.1038/d41586-024-03958-2"
        ]
    },
    {
        "URL": "https://www.nature.com/articles/d41586-024-03957-3",
        "title": "DeepMind AI weather forecaster beats world-class system",
        "content": [
            "*A_satellite_photo_of_typhoon_Hagibis_approaching_Japan",
            "Typhoon Hagibis approaches Japan in 2019. The storm was one of the events used to study the accuracy of an AI-based forecasting system.Credit: NASA Worldview, Earth Observing System Data and Information System (EOSDIS)/AP/Alamy",
            "Google DeepMind has developed the first artificial intelligence (AI) model of its kind to predict the weather more accurately than the best system currently in use. The model generates forecasts up to 15 days in advance \u2014 and it does so in minutes, rather than the hours needed by today\u2019s forecasting programs. ",
            "The purely AI system beats the world\u2019s best medium-range operational model, the European Centre for Medium-Range Weather Forecasts\u2019 ensemble model (ENS), at predicting extreme weather such as hurricanes and heatwaves. The breakthrough could help usher in an era of AI weather forecasting that is quicker and more reliable than today\u2019s systems, researchers say. The system, called GenCast, is described today in Nature1.",
            "Superfast Microsoft AI is first to predict air pollution for the whole world",
            "Conventional forecasts, including those from ENS, are based on mathematical models that simulate the laws of physics governing Earth\u2019s atmosphere. They use supercomputers to crunch data from satellites and weather stations \u2014 a process that takes hours and vast amounts of computing power.",
            "GenCast, by contrast, has been trained only on historical weather data, which enables the system to draw out complex relationships between variables such as air pressure, humidity, temperature and wind. This helps it to outperform strictly physics-based systems, says Ilan Price, a research scientist at Google DeepMind in London and an author of the paper. ",
            "\u201cWe\u2019ve really made dramatic progress to catch up and now overtake [physics-based models] with machine learning,\u201d Price says. ",
            "h2AI surge",
            "AI weather forecasting has advanced rapidly, with multiple companies racing to develop new and better models. Among them are Huawei2 in Shenzhen, China, and Nvidia in Santa Clara, California. Earlier this year, Google released NeuralGCM3, a hybrid system that combines physics-based models with AI to produce short- and long-term forecasts on a par with conventional models. ",
            "Some of the AI systems released to date are \u2018deterministic\u2019 models, meaning that they offer only a single forecast and do not estimate the likelihood that the forecast will be correct. By contrast, GenCast generates \u2018ensemble\u2019 forecasts: a suite of forecasts that have each been produced from slightly different starting conditions. By combining these forecasts into an ensemble, scientists can produce a final forecast and estimate the probability that the forecasted weather will occur.",
            "How machine learning could help to improve climate forecasts",
            "Price and his colleagues trained the AI on global weather data from 1979 to 2018 and then predicted the weather of 2019. To check its accuracy, they compared GenCast forecasts with actual weather data and ENS forecasts for that year.",
            "GenCast was more accurate than ENS on 97% of the measures used on a scorecard to evaluate such \u2018probabilistic\u2019 forecasts. It was also better at forecasting extreme heat, cold and wind, as well as tropical-cyclone tracks. ",
            "GenCast produces one 15-day forecast within 8 minutes on an AI processing chip. This speed is \u201cquite substantially faster\u201d than the time it takes conventional models, Price says.",
            "h2Code for all",
            "The researchers have released the underlying code and are making model parameters called \u2018weights\u2019 available for non-commercial use. Price says this will help to \u201cdemocratize\u201d research and increase public access to weather modelling. ",
            "\u201cThis is a really great contribution to open science,\u201d says Matthew Chantry, a machine-learning coordinator at the European Centre For Medium-Range Weather Forecasts in Reading, UK. \u201cWe need to understand how these models perform in the most extreme weather events\u201d, and publishing the model and data publicly will allow the research community to assess them, he says. ",
            "Chantry read a manuscript of the paper when it was posted on a preprint archive last year and was inspired by GenCast\u2019s \u2018diffusion\u2019 approach, which introduces random noise into the model to refine its reliability. \u201cWe\u2019ve actually implemented some of the key breakthroughs in our own machine-learning model,\u201d he says. The resulting model, called Artificial Intelligence/Integrated Forecasting System (AIFS), will be published soon, he adds. ",
            "Having more accurate forecasts sooner can help people make informed decisions, Price says, especially for those living in the path of a hurricane.",
            "doi: https://doi.org/10.1038/d41586-024-03957-3"
        ]
    },
    {
        "URL": "https://www.nature.com/articles/d41586-024-01684-3",
        "title": "Virtual lab powered by \u2018AI scientists\u2019 super-charges biomedical research",
        "content": [
            "*Illustration_of_antibodies_red_and_blue_responding_to_SARS-CoV-2_purple",
            "The virtual lab set-up used several LLMs to design antibody fragments that could bind to SARS-CoV-2.Credit: KTSDESIGN/Science Photo Library via Getty",
            "In an effort to automate scientific discovery using artificial intelligence (AI), researchers have created a virtual laboratory that combines several \u2018AI scientists\u2019 \u2014 large language models with defined scientific roles \u2014 that can collaborate to achieve goals set by human researchers.",
            "The system, described in a preprint posted on bioRxiv last month1, was able to design antibody fragments called nanobodies that can bind to the virus that causes COVID-19, proposing nearly 100 of these structures in a fraction of the time it would take an all-human research group. ",
            "Researchers built an \u2018AI Scientist\u2019 \u2014 what can it do?",
            " \u201cThese virtual-lab AI agents have shown to be quite capable at doing a lot of tasks,\u201d says study co-author James Zou, a computational biologist at Stanford University in California. \u201cWe\u2019re quite excited about exploring the potential of the virtual lab across different scientific domains.\u201d",
            "The experiment \u201crepresents a new paradigm of taking AI as collaborators, not just tools\u201d, says Yanjun Gao, who researches the health-care applications of AI at the University of Colorado Anschutz Medical Campus in Aurora. But she adds that human input and oversight are still crucial. \u201cI don\u2019t think at this stage we can fully trust the AI to make decisions.\u201d",
            "h2Interdisciplinary AI",
            "Scientists worldwide have explored the potential of large language models (LLMs) to speed up research \u2014 including creating an \u2018AI scientist\u2019 that can carry out parts of the scientific process, from generating hypotheses and designing experiments to drafting papers. But Zou says that most studies have focused on the application of LLMs for experiments with a narrow scope, rather than exploring their potential in interdisciplinary research. He and his colleagues set up the virtual lab to combine expertise from different fields. ",
            "They began by training two LLMs for their virtual team: the team-leading principal investigator (PI), which has expertise in AI for research, and a \u2018scientific critic\u2019 to catch errors and oversights from other LLMs throughout the process. The authors gave these LLMs a goal \u2014 designing new nanobodies to target the virus SARS-CoV-2 \u2014 and instructed them to develop other LLMs that could achieve it. ",
            "\u2018A landmark moment\u2019: scientists use AI to design antibodies from scratch",
            "The PI then created and trained three further AI scientist agents to support the research efforts. Each of these \u2018scientists\u2019 was trained in a particular discipline \u2014 immunology, computational biology or machine learning. \u201cThese different agents would have different expertise, and they would work together in solving different kinds of scientific problems,\u201d says Zou. ",
            "The AI agents worked independently on tasks allocated by the virtual PI, such as calculating parameters or writing code for a new machine-learning model. They could also make use of other AI research tools, such as the protein-design tools AlphaFold and Rosetta. A human researcher guided the LLMs through regular \u2018team meetings\u2019 to evaluate their progress. ",
            "doi: https://doi.org/10.1038/d41586-024-01684-3"
        ]
    },
    {
        "URL": "https://www.nature.com/articles/d41586-024-03905-1",
        "title": "How close is AI to human-level intelligence?",
        "content": [
            "*Abstract_illustration_showing_a_brain_being_formed_from_data_surrounded_by_representations_of_3D_map",
            " Illustration: Petra P\u00e9terffy",
            "OpenAI\u2019s latest artificial intelligence (AI) system dropped in September with a bold promise. The company behind the chatbot ChatGPT showcased o1 \u2014 its latest suite of large language models (LLMs) \u2014 as having a \u201cnew level of AI capability\u201d. OpenAI, which is based in San Francisco, California, claims that o1 works in a way that is closer to how a person thinks than do previous LLMs.",
            "The release poured fresh fuel on a debate that\u2019s been simmering for decades: just how long will it be until a machine is capable of the whole range of cognitive tasks that human brains can handle, including generalizing from one task to another, abstract reasoning, planning and choosing which aspects of the world to investigate and learn from?",
            "Bigger AI chatbots more inclined to spew nonsense \u2014 and people don\u2019t always realize",
            "Such an \u2018artificial general intelligence\u2019, or AGI, could tackle thorny problems, including climate change, pandemics and cures for cancer, Alzheimer\u2019s and other diseases. But such huge power would also bring uncertainty \u2014 and pose risks to humanity. \u201cBad things could happen because of either the misuse of AI or because we lose control of it,\u201d says Yoshua Bengio, a deep-learning researcher at the University of Montreal, Canada.",
            "The revolution in LLMs over the past few years has prompted speculation that AGI might be tantalizingly close. But given how LLMs are built and trained, they will not be sufficient to get to AGI on their own, some researchers say. \u201cThere are still some pieces missing,\u201d says Bengio.",
            "What\u2019s clear is that questions about AGI are now more relevant than ever. \u201cMost of my life, I thought people talking about AGI are crackpots,\u201d says Subbarao Kambhampati, a computer scientist at Arizona State University in Tempe. \u201cNow, of course, everybody is talking about it. You can\u2019t say everybody\u2019s a crackpot.\u201d",
            "h2Why the AGI debate changed",
            "The phrase artificial general intelligence entered the zeitgeist around 2007 after its mention in an eponymously named book edited by AI researchers Ben Goertzel and Cassio Pennachin. Its precise meaning remains elusive, but it broadly refers to an AI system with human-like reasoning and generalization abilities. Fuzzy definitions aside, for most of the history of AI, it\u2019s been clear that we haven\u2019t yet reached AGI. Take AlphaGo, the AI program created by Google DeepMind to play the board game Go. It beats the world\u2019s best human players at the game \u2014 but its superhuman qualities are narrow, because that\u2019s all it can do.",
            "The new capabilities of LLMs have radically changed the landscape. Like human brains, LLMs have a breadth of abilities that have caused some researchers to seriously consider the idea that some form of AGI might be imminent1, or even already here.",
            "This breadth of capabilities is particularly startling when you consider that researchers only partially understand how LLMs achieve it. An LLM is a neural network, a machine-learning model loosely inspired by the brain; the network consists of artificial neurons, or computing units, arranged in layers, with adjustable parameters that denote the strength of connections between the neurons. During training, the most powerful LLMs \u2014 such as o1, Claude (built by Anthropic in San Francisco) and Google\u2019s Gemini \u2014 rely on a method called next token prediction, in which a model is repeatedly fed samples of text that has been chopped up into chunks known as tokens. These tokens could be entire words or simply a set of characters. The last token in a sequence is hidden or \u2018masked\u2019 and the model is asked to predict it. The training algorithm then compares the prediction with the masked token and adjusts the model\u2019s parameters to enable it to make a better prediction next time.",
            "How AI is reshaping science and society",
            "The process continues \u2014 typically using billions of fragments of language, scientific text and programming code \u2014 until the model can reliably predict the masked tokens. By this stage, the model parameters have captured the statistical structure of the training data, and the knowledge contained therein. The parameters are then fixed and the model uses them to predict new tokens when given fresh queries or \u2018prompts\u2019 that were not necessarily present in its training data, a process known as inference.",
            "The use of a type of neural network architecture known as a transformer has taken LLMs significantly beyond previous achievements. The transformer allows a model to learn that some tokens have a particularly strong influence on others, even if they are widely separated in a sample of text. This permits LLMs to parse language in ways that seem to mimic how humans do it \u2014 for example, differentiating between the two meanings of the word \u2018bank\u2019 in this sentence: \u201cWhen the river\u2019s bank flooded, the water damaged the bank\u2019s ATM, making it impossible to withdraw money.\u201d",
            "This approach has turned out to be highly successful in a wide array of contexts, including generating computer programs to solve problems that are described in natural language, summarizing academic articles and answering mathematics questions.",
            "And other new capabilities have emerged along the way, especially as LLMs have increased in size, raising the possibility that AGI, too, could simply emerge if LLMs get big enough. One example is chain-of-thought (CoT) prompting. This involves showing an LLM an example of how to break down a problem into smaller steps to solve it, or simply asking the LLM to solve a problem step-by-step. CoT prompting can lead LLMs to correctly answer questions that previously flummoxed them. But the process doesn\u2019t work very well with small LLMs.",
            "h2The limits of LLMs",
            "CoT prompting has been integrated into the workings of o1, according to OpenAI, and underlies the model\u2019s prowess. Francois Chollet, who was an AI researcher at Google in Mountain View, California, and left in November to start a new company, thinks that the model incorporates a CoT generator that creates numerous CoT prompts for a user query and a mechanism to select a good prompt from the choices. During training, o1 is taught not only to predict the next token, but also to select the best CoT prompt for a given query. The addition of CoT reasoning explains why, for example, o1-preview \u2014 the advanced version of o1 \u2014 correctly solved 83% of problems in a qualifying exam for the International Mathematical Olympiad, a prestigious mathematics competition for high-school students, according to OpenAI. That compares with a score of just 13% for the company\u2019s previous most powerful LLM, GPT-4o.",
            "In AI, is bigger always better?",
            "But, despite such sophistication, o1 has its limitations and does not constitute AGI, say Kambhampati and Chollet. On tasks that require planning, for example, Kambhampati\u2019s team has shown that although o1 performs admirably on tasks that require up to 16 planning steps, its performance degrades rapidly when the number of steps increases to between 20 and 402. Chollet saw similar limitations when he challenged o1-preview with a test of abstract reasoning and generalization that he designed to measure progress towards AGI. The test takes the form of visual puzzles. Solving them requires looking at examples to deduce an abstract rule and using that to solve new instances of a similar puzzle, something humans do with relative ease.",
            "LLMs, says Chollet, irrespective of their size, are limited in their ability to solve problems that require recombining what they have learnt to tackle new tasks. \u201cLLMs cannot truly adapt to novelty because they have no ability to basically take their knowledge and then do a fairly sophisticated recombination of that knowledge on the fly to adapt to new context.\u201d",
            "h2Can LLMs deliver AGI?",
            "So, will LLMs ever deliver AGI? One point in their favour is that the underlying transformer architecture can process and find statistical patterns in other types of information in addition to text, such as images and audio, provided that there is a way to appropriately tokenize those data. Andrew Wilson, who studies machine learning at New York University in New York City, and his colleagues showed that this might be because the different types of data all share a feature: such data sets have low \u2018Kolmogorov complexity\u2019, defined as the length of the shortest computer program that\u2019s required to create them3. The researchers also showed that transformers are well-suited to learning about patterns in data with low Kolmogorov complexity and that this suitability grows with the size of the model. Transformers have the capacity to model a wide swathe of possibilities, increasing the chance that the training algorithm will discover an appropriate solution to a problem, and this \u2018expressivity\u2019 increases with size. These are, says Wilson, \u201csome of the ingredients that we really need for universal learning\u201d. Although Wilson thinks AGI is currently out of reach, he says that LLMs and other AI systems that use the transformer architecture have some of the key properties of AGI-like behaviour.",
            "Can AI review the scientific literature \u2014 and figure out what it all means?",
            "Yet there are also signs that transformer-based LLMs have limits. For a start, the data used to train the models are running out. Researchers at Epoch AI, an institute in San Francisco that studies trends in AI, estimate4 that the existing stock of publicly available textual data used for training might run out somewhere between 2026 and 2032. There are also signs that the gains being made by LLMs as they get bigger are not as great as they once were, although it\u2019s not clear if this is related to there being less novelty in the data because so many have now been used, or something else. The latter would bode badly for LLMs.",
            "Raia Hadsell, vice-president of research at Google DeepMind in London, raises another problem. The powerful transformer-based LLMs are trained to predict the next token, but this singular focus, she argues, is too limited to deliver AGI. Building models that instead generate solutions all at once or in large chunks could bring us closer to AGI, she says. The algorithms that could help to build such models are already at work in some existing, non-LLM systems, such as OpenAI\u2019s DALL-E, which generates realistic, sometimes trippy, images in response to descriptions in natural language. But they lack LLMs\u2019 broad suite of capabilities.",
            "h2Build me a world model",
            "The intuition for what breakthroughs are needed to progress to AGI comes from neuroscientists. They argue that our intelligence is the result of the brain being able to build a \u2018world model\u2019, a representation of our surroundings. This can be used to imagine different courses of action and predict their consequences, and therefore to plan and reason. It can also be used to generalize skills that have been learnt in one domain to new tasks by simulating different scenarios.",
            "Several reports have claimed evidence for the emergence of rudimentary world models inside LLMs. In one study5, researchers Wes Gurnee and Max Tegmark at the Massachusetts Institute of Technology in Cambridge claimed that a widely used open-source family of LLMs developed internal representations of the world, the United States and New York City when trained on data sets containing information about these places, although other researchers noted on X (formerly Twitter) that there was no evidence that the LLMs were using the world model for simulations or to learn causal relationships. In another study6, Kenneth Li, a computer scientist at Harvard University in Cambridge and his colleagues reported evidence that a small LLM trained on transcripts of moves made by players of the board game Othello learnt to internally represent the state of the board and used this to correctly predict the next legal move.",
            "Other results, however, show how world models learnt by today\u2019s AI systems can be unreliable. In one such study7, computer scientist Keyon Vafa at Harvard University, and his colleagues used a gigantic data set of the turns taken during taxi rides in New York City to train a transformer-based model to predict the next turn in a sequence, which it did with almost 100% accuracy.",
            "By examining the turns the model generated, the researchers were able to show that it had constructed an internal map to arrive at its answers. But the map bore little resemblance to Manhattan (see \u2018The impossible streets of AI\u2019), \u201ccontaining streets with impossible physical orientations and flyovers above other streets\u201d, the authors write. \u201cAlthough the model does do well in some navigation tasks, it\u2019s doing well with an incoherent map,\u201d says Vafa. And when the researchers tweaked the test data to include unforeseen detours that were not present in the training data, it failed to predict the next turn, suggesting that it was unable to adapt to new situations.",
            "*The_impossible_streets_of_AI_The_results_of_an_AI_system_that_was_trained_to_predict_routes_taken_by",
            "Source: Ref. 7",
            "h2The importance of feedback",
            "One important feature that today\u2019s LLMs lack is internal feedback, says Dileep George, a member of the AGI research team at Google DeepMind in Mountain View, California. The human brain is full of feedback connections that allow information to flow bidirectionally between layers of neurons. This allows information to flow from the sensory system to higher layers of the brain to create world models that reflect our environment. It also means that information from the world models can ripple back down and guide the acquisition of further sensory information. Such bidirectional processes lead, for example, to perceptions, wherein the brain uses world models to deduce the probable causes of sensory inputs. They also enable planning, with world models used to simulate different courses of action.",
            "But current LLMs are able to use feedback only in a tacked-on way. In the case of o1, the internal CoT prompting that seems to be at work \u2014 in which prompts are generated to help answer a query and fed back to the LLM before it produces its final answer \u2014 is a form of feedback connectivity. But, as seen with Chollet\u2019s tests of o1, this doesn\u2019t ensure bullet-proof abstract reasoning.",
            "Why scientists trust AI too much \u2014 and what to do about it",
            "Researchers, including Kambhampati, have also experimented with adding external modules, called verifiers, onto LLMs. These check answers that are generated by an LLM in a specific context, such as for creating viable travel plans, and ask the LLM to rerun the query if the answer is not up to scratch8. Kambhampati\u2019s team showed that LLMs aided by external verifiers were able to create travel plans significantly better than were vanilla LLMs. The problem is that researchers have to design bespoke verifiers for each task. \u201cThere is no universal verifier,\u201d says Kambhampati. By contrast, an AGI system that used this approach would probably need to build its own verifiers to suit situations as they arise, in much the same way that humans can use abstract rules to ensure they are reasoning correctly, even for new tasks.",
            "Efforts to use such ideas to help produce new AI systems are in their infancy. Bengio, for example, is exploring how to create AI systems with different architectures to today\u2019s transformer-based LLMs. One of these, which uses what he calls generative flow networks, would allow a single AI system to learn how to simultaneously build world models and the modules needed to use them for reasoning and planning.",
            "Another big hurdle encountered by LLMs is that they are data guzzlers. Karl Friston, a theoretical neuroscientist at University College London, suggests that future systems could be made more efficient by giving them the ability to decide just how much data they need to sample from the environment to construct world models and make reasoned predictions, rather than simply ingesting all the data they are fed. This, says Friston, would represent a form of agency or autonomy, which might be needed for AGI. \u201cYou don\u2019t see that kind of authentic agency, in say, large language models, or generative AI,\u201d he says. \u201cIf you\u2019ve got any kind of intelligent artefact that can select at some level, I think you\u2019re making an important move towards AGI,\u201d he adds.",
            "AI systems with the ability to build effective world models and integrated feedback loops might also rely less on external data because they could generate their own by running internal simulations, positing counterfactuals and using these to understand, reason and plan. Indeed, in 2018, researchers David Ha, then at Google Brain in Tokyo, and J\u00fcrgen Schmidhuber at the Dalle Molle Institute for Artificial Intelligence Studies in Lugano-Viganelllo, Switzerland, reported9 building a neural network that could efficiently build a world model of an artificial environment, and then use it to train the AI to race virtual cars.",
            "Do AI models produce more original ideas than researchers?",
            "If you think that AI systems with this level of autonomy sound scary, you are not alone. As well as researching how to build AGI, Bengio is an advocate of incorporating safety into the design and regulation of AI systems. He argues that research must focus on training models that can guarantee the safety of their own behaviour \u2014 for instance, by having mechanisms that calculate the probability that the model is violating some specified safety constraint and reject actions if the probability is too high. Also, governments need to ensure safe use. \u201cWe need a democratic process that makes sure individuals, corporations, even the military, use AI and develop AI in ways that are going to be safe for the public,\u201d he says.",
            "So will it ever be possible to achieve AGI? Computer scientists say there is no reason to think otherwise. \u201cThere are no theoretical impediments,\u201d says George. Melanie Mitchell, a computer scientist at the Santa Fe Institute in New Mexico, agrees. \u201cHumans and some other animals are a proof of principle that you can get there,\u201d she says. \u201cI don\u2019t think there\u2019s anything particularly special about biological systems versus systems made of other materials that would, in principle, prevent non-biological systems from becoming intelligent.\u201d",
            "But, even if it is possible there is little consensus about how close its arrival might be: estimates range from just a few years from now to at least ten years away. If an AGI system is created, George says, we\u2019ll know it when we see it. Chollet suspects it will creep up on us. \u201cWhen AGI arrives, it\u2019s not going to be as noticeable or as groundbreaking as you might think,\u201d he says. \u201cIt will take time for AGI to realize its full potential. It will be invented first. Then, you will need to scale it up and apply it before it starts really changing the world.\u201d",
            "Nature 636, 22-25 (2024)",
            "doi: https://doi.org/10.1038/d41586-024-03905-1"
        ]
    },
    {
        "URL": "https://www.nature.com/articles/d41586-024-03939-5",
        "title": "Huge randomized trial of AI boosts discovery \u2014 at least for good scientists",
        "content": [
            "*A_researcher_pictured_using_a_FTIR_spectrophotometer",
            "Scientists at an unnamed corporate laboratory were randomly assigned a machine-learning tool.Credit: Eugenio Marongiu/Getty",
            "Artificial intelligence (AI) is becoming ubiquitous in applied research, but can it actually invent useful materials faster than humans can? It is still too early to tell, but a massive study suggests that it might.",
            "doi: https://doi.org/10.1038/d41586-024-03939-5"
        ]
    },
    {
        "URL": "https://www.nature.com/articles/d41586-024-04017-6",
        "title": "A science mega-programme is taking shape in the EU: what it means for researchers",
        "content": [
            "*Commissioners-Designate_Ekaterina_Zakharieva_speaks_during_a_European_Parliament_hearing_in_Belgium",
            "EU research commissioner Ekaterina Zakharieva held positions in the Bulgarian government.Credit: Thierry Monasse/Getty",
            "The European Union has a new research head, tasked with reshaping the world\u2019s biggest collaborative research programme to help stop the bloc\u2019s economic and technological downward slide.",
            "Ekaterina Zaharieva, a lawyer who has held multiple positions in the Bulgarian government \u2014 albeit none related to science \u2014 became commissioner for start-ups, research and innovation on 1 December.",
            "For scientists, the focus will be on how Zaharieva helps to shape the EU\u2019s next multibillion-euro science programme, the follow-up to the \u20ac95.5-billion (US$101-billion) Horizon Europe scheme. The programme includes the bloc\u2019s premier basic-science funder, the European Research Council (ERC). But there is increasing focus on strengthening industry involvement in the scheme to boost innovation.",
            "\u201cWe definitely attract the best players from academia now with the ERC,\u201d says Sylvia Schwaag Serger, a research and innovation specialist at Lund University in Sweden. But other parts of the programme haven\u2019t attracted the \u201cbest players\u201d from industry, she says.",
            "There needs to be \u201cmuch more private investment in research\u201d, says Conny Aerts, an astrophysicist at the Catholic University of Leuven (KU Leuven) in Belgium. \u201cThis is very low in a European context compared to other continents.\u201d Aerts and Schwaag Serger are members of an expert group appointed by the European Commission that in October made recommendations for the successor scheme, known as Framework Programme 10 (FP10).",
            "h2Technological anxieties",
            "Zaharieva\u2019s appointment is part of a five-yearly shake-up of the commission, the EU\u2019s powerful executive body. The new term comes as the EU faces growing tensions with Russia and an uncertain relationship with the United States. The bloc is also desperate to improve its economic performance and wean itself off its dependence on US and Chinese technologies.",
            "Commission president Ursula von der Leyen has said that she will prioritize science during her second five-year term to achieve that goal. \u201cWe will put research and innovation, science and technology at the heart of our economy,\u201d she said in a speech last week. How she will do that and how much money she will have to do so is still unclear. The commission is expected to release an official proposal on FP10 next year.",
            "As part of this push to turn research into economic growth, there are already some notable changes. For the first time, the commissioner\u2019s title includes \u2018start-ups\u2019, reflecting the increased focus on businesses. The commission is also mulling more funding for \u2018dual-use science\u2019, which could be used for military purposes.",
            "h2Basic-science boost?",
            "The good news for researchers is that there\u2019s universal support for the European Research Council, which gives out prestigious grants of \u20ac1.5 million to \u20ac2.5 million over five years.",
            "\u201cThe ERC has become essential to the competitiveness of European science,\u201d concluded a key report written for the commission by Mario Draghi, a former prime minister of Italy, whose recommendations will underpin von der Leyen\u2019s term. Draghi wants the ERC\u2019s roughly \u20ac2-billion annual budget to double.",
            "*President_of_the_European_Commission_Ursula_von_der_Leyen_rings_a_small_bell_during_a_weekly_meeting",
            "European Commission President Ursula von der Leyen has promised to \u201cexpand\u201d the European Research Council, the prestigious grant-funder.Credit: Thierry Monasse/Getty",
            "A boost is essential, because the ERC is under severe strain, says its president Maria Leptin. \u201cOur grants have not increased in size since 2007,\u201d she says. \u201cThey\u2019ve lost in value.\u201d An ERC spokesperson estimated that inflation has eroded their real worth by around 40%.",
            "But the ERC cannot increase the size of its grants, because this would mean it couldn\u2019t award as many. And that would mean reductions to an already-low success rate of 14%, which has begun to put off top scientists, Leptin says.",
            "Von der Leyen has promised to \u201cexpand\u201d the ERC during her term. But by how much will depend on the outcome of budget negotiations next year with the EU\u2019s member countries, whose own finances are under strain, owing in part to defence spending.",
            "h2Industry focus",
            "The future of other parts of the EU\u2019s research programme are less clear. Some \u20ac53 billion of Horizon Europe\u2019s budget goes largely to directed, applied-research calls in areas such as climate science, space, health and security. These try to build continent-spanning consortia between academics and companies.",
            "But these streams aren\u2019t attracting industry leaders. \u201cIt is very bureaucratic,\u201dsays Schwaag Serger. \u201cIt\u2019s a lot of cost involved for companies to participate in the framework programme, both to prepare them to apply, but also to administer,\u201d she says.",
            "The solution, say Schwaag Serger and her group, is to set up an \u2018Industrial Competitiveness and Technology Council\u2019, an independent body led by top business figures that steer a more useful research agenda. \u201cOne of the ambitions,\u201d she says, \u201cis to follow the model of the ERC.\u201d",
            "h2Brain drain",
            "The EU itself can only do so much to improve the bloc\u2019s performance. Most of the region\u2019s research-and-development spending still comes through national governments and private companies. On this measure, the bloc lags behind the United States and Japan.",
            "And although the EU loses fewer researchers to other regions than it did a decade ago, a serious brain drain persists, mostly to the United States, according to the expert panel\u2019s report.",
            "\u201cThe problem is that tenure-track positions are very scarce in Europe,\u201d says Mona Simion, a philosopher at the University of Glasgow, UK, and a board member of the Young Academy of Europe, a science-policy group.",
            "The commission, with national governments, should set up a scheme that puts excellent young researchers on a tenure track, she argues. \u201cEurope, on a regular basis, loses its best researchers.\u201d",
            "doi: https://doi.org/10.1038/d41586-024-04017-6"
        ]
    },
    {
        "URL": "https://www.nature.com/articles/d41586-024-03982-2",
        "title": "Wuhan lab samples hold no close relatives to virus behind COVID",
        "content": [
            "*Shi_Zhengli_wearing_protective_clothing_in_a_biosafety_lab",
            "Chinese virologist Shi Zhengli has presented evidence that her lab has not worked with close relatives of SARS-CoV-2.Credit: Johannes Eisele/AFP via Getty",
            "After years of rumours that the virus that causes COVID-19 escaped from a laboratory in China, the virologist at the centre of the claims has presented data on dozens of new coronaviruses collected from bats in southern China. At a conference in Japan this week, Shi Zhengli, a specialist on bat coronaviruses, reported that none of the viruses stored in her freezers are the most recent ancestors of the virus SARS-CoV-2.",
            "doi: https://doi.org/10.1038/d41586-024-03982-2"
        ]
    },
    {
        "URL": "https://www.nature.com/articles/d41586-024-03968-0",
        "title": "Sick animals suggest COVID pandemic started in Wuhan market",
        "content": [
            "*Close_up_of_a_raccoon_dog_in_a_cage_in_rural_China",
            "Raccoon dogs are among the animals susceptible to SARS-CoV-2 that were present at the Chinese market where the virus is thought to have jumped to humans.Credit: YongXin Zhang/Alamy",
            "The quest to understand where the COVID-19 pandemic started has revealed fresh clues. Researchers have re-analysed data collected from a market in Wuhan, China, during the early days of the pandemic and found that animals there were infected with a virus \u2013 although they could not confirm what exactly caused the infection.",
            "\u201cThe conclusion is convincing that there was infection in the animals,\u201d says Spyros Lytras, an evolutionary virologist at the University of Tokyo. The results, which have not been peer reviewed, were presented at a conference, Preparing for the Next Pandemic: Evolution, Pathogenesis and Virology of Coronaviruses, in Awaji, Japan, on 3 December.",
            "Many of the first COVID-19 cases to be identified were linked to Wuhan\u2019s Huanan Seafood Wholesale Market. Some studies have reasoned that people brought the virus to the market, where they passed it on to others, whereas other studies have suggested that the market was the site of the first spillover events, in which animals with the virus first infected people1. Although these earlier studies established the presence of animals susceptible to the virus that causes COVID-19, and the virus itself, at the market, they were not able to confirm that the animals were infected with the virus2.",
            "\u201cThe missing link in the whole zoonotic story has been the animal,\u201d says Edward Holmes, a virologist at the University of Sydney in Australia. \u201cIf you can show there are infected animals at the market, then the story is complete,\u201d he says, referring specifically to animals infected with a progenitor of SARS-CoV-2.",
            "The latest analysis suggests that infected animals were at the market at the same time that early cases of COVID-19 emerged there. \u201cThis is one more piece of indirect evidence that suggests a connection of the origin of the SARS-CoV-2 pandemic with the Huanan market,\u201d says Christian Drosten, a virologist at the Charit\u00e9 University Hospital in Berlin.",
            "Most researchers agree that SARS-CoV-2 originated in animals. However, because a progenitor of the virus has not been found in an animal, some have continued to argue that the virus could have escaped \u2014 either by accident or through deliberate release \u2014 from the Wuhan Institute of Virology. A detailed report released by the Republican-majority select committee of the US House of Representatives earlier this week concluded that the pandemic \u201cmost likely emerged from a laboratory in Wuhan\u201d.",
            "h2Infected animals",
            "Shortly after the Huanan market was shut down on 1 January 2020, a group of researchers from the Chinese Center for Disease Control and Prevention in Beijing visited the market and swabbed stalls, walls, bins, sewage wells and animal products stored in freezers. They sequenced DNA and RNA from those swabs and deposited the resulting data into a genomic database.",
            "Angela Rasmussen, a virologist at the University of Saskatchewan in Saskatoon, Canada, wanted to look more closely at the data for potential animal intermediates. She studied the genomic data of animals found at the market that are susceptible to SARS-CoV-2. These included American mink (Neogale vison), ermine (Mustela erminea), masked palm civets (Paguma larvata), raccoon dogs (Nyctereutes procyonoides), red foxes (Vulpes vulpes) and greater hog badgers (Arctonyx collaris).",
            "doi: https://doi.org/10.1038/d41586-024-03968-0"
        ]
    },
    {
        "URL": "https://www.nature.com/articles/d41586-024-03936-8",
        "title": "What is ageing? Even the field\u2019s researchers can\u2019t agree",
        "content": [
            "*Young_and_old_hands_on_a_black_background_show_the_contrast_of_ageing",
            "When ageing begins is one of many questions researchers cannot agree on.Credit: mrPliskin/iStock via Getty",
            "Researchers studying ageing disagree on just about everything \u2014 including what ageing is, whether it is a disease and when it starts \u2014 according to a survey of about 100 scientists working in the field.",
            "doi: https://doi.org/10.1038/d41586-024-03936-8"
        ]
    }
]